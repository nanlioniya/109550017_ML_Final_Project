{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install feature_engine","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:35:52.877714Z","iopub.execute_input":"2023-01-09T09:35:52.878209Z","iopub.status.idle":"2023-01-09T09:36:04.414839Z","shell.execute_reply.started":"2023-01-09T09:35:52.878172Z","shell.execute_reply":"2023-01-09T09:36:04.413348Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Requirement already satisfied: feature_engine in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from feature_engine) (1.0.2)\nRequirement already satisfied: pandas>=1.0.3 in /opt/conda/lib/python3.7/site-packages (from feature_engine) (1.3.5)\nRequirement already satisfied: statsmodels>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from feature_engine) (0.13.2)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from feature_engine) (1.7.3)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.7/site-packages (from feature_engine) (1.21.6)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.0.3->feature_engine) (2022.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0.0->feature_engine) (1.0.1)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.2)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.11.1->feature_engine) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=21.3->statsmodels>=0.11.1->feature_engine) (3.0.9)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature_engine) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nimport feature_engine as fe\nfrom feature_engine.encoding import WoEEncoder\nfrom colorama import Fore, Back, Style\nimport xgboost\nimport random\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.linear_model import LogisticRegression,HuberRegressor\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler,PowerTransformer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.metrics import r2_score,roc_auc_score\nfrom imblearn.under_sampling import NearMiss, ClusterCentroids\nfrom imblearn.over_sampling import SMOTE\n\nsns.set()\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:04.417614Z","iopub.execute_input":"2023-01-09T09:36:04.418029Z","iopub.status.idle":"2023-01-09T09:36:04.430380Z","shell.execute_reply.started":"2023-01-09T09:36:04.417977Z","shell.execute_reply":"2023-01-09T09:36:04.428719Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-aug-2022/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-aug-2022/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:04.432020Z","iopub.execute_input":"2023-01-09T09:36:04.432477Z","iopub.status.idle":"2023-01-09T09:36:04.675355Z","shell.execute_reply.started":"2023-01-09T09:36:04.432440Z","shell.execute_reply":"2023-01-09T09:36:04.674040Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"target = train.pop('failure')\ndata = pd.concat([train, test])\nfeature = [f for f in data.columns if f.startswith('measurement') or f=='loading']\nnullValue_cols = [col for col in train.columns if train[col].isnull().sum()!=0]","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:04.678939Z","iopub.execute_input":"2023-01-09T09:36:04.679513Z","iopub.status.idle":"2023-01-09T09:36:04.712304Z","shell.execute_reply.started":"2023-01-09T09:36:04.679465Z","shell.execute_reply":"2023-01-09T09:36:04.710813Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def data_pre_processing(data):\n\n    data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n    data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n    data['area'] = data['attribute_2'] * data['attribute_3']\n    data['loading'] = np.log(data['loading']) #The loading feature seems to have right skewed distribution.\n                                              #Let's apply log transformation to make the distribution more normal.\n    data['count_null'] = data.isnull().sum(axis=1)\n\n    full_fill_dict ={}\n    full_fill_dict['measurement_17'] = {\n        'A': ['measurement_5','measurement_6','measurement_8','measurement_7'],\n        'B': ['measurement_4','measurement_5','measurement_7','measurement_9'],\n        'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n        'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n        'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n        'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n        'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n        'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n        'I': ['measurement_3','measurement_7','measurement_8','measurement_9']\n    }\n\n\n    # collect the name of the next 10 best measurement columns sorted by correlation (except 17 already done above):\n    col = [col for col in test.columns if 'measurement' not in col]+ ['loading','m3_missing','m5_missing']\n    a = []\n    b =[]\n\n    for x in range(3,17):\n        corr = np.absolute(data.drop(col, axis=1).corr()[f'measurement_{x}']).sort_values(ascending=False)\n        a.append(np.round(np.sum(corr[1:4]),3)) # we add the 3 first lines of the correlation values to get the \"most correlated\"\n        b.append(f'measurement_{x}')\n\n    c = pd.DataFrame()\n    c['Selected columns'] = b\n    c['correlation total'] = a\n    c = c.sort_values(by = 'correlation total',ascending=False).reset_index(drop = True)\n    # calculating top 4 correlated features for each measurement column w.r.t each product code\n\n    for i in range(10):\n        measurement_col = 'measurement_' + c.iloc[i,0][12:] # we select the next best correlated column \n        fill_dict = {}\n        for x in data.product_code.unique() : \n            corr = np.absolute(data[data.product_code == x].drop(col, axis=1)\n                               .corr()[measurement_col]).sort_values(ascending=False)\n            measurement_col_dic = {}\n            measurement_col_dic[measurement_col] = corr[1:5].index.tolist()\n            fill_dict[x] = measurement_col_dic[measurement_col]\n        full_fill_dict[measurement_col] =fill_dict\n\n    for code in data.product_code.unique():\n        total_na_filled_by_linear_model = 0\n        for measurement_col in list(full_fill_dict.keys()):\n            tmp = data[data.product_code == code]\n            column = full_fill_dict[measurement_col][code]\n            tmp_train = tmp[column+[measurement_col]].dropna(how='any')\n            tmp_test = tmp[(tmp[column].isnull().sum(axis=1)==0)&(tmp[measurement_col].isnull())]\n\n            model = HuberRegressor(epsilon=1.5)\n            model.fit(tmp_train[column], tmp_train[measurement_col])\n            data.loc[(data.product_code==code)&(data[column].isnull().sum(axis=1)==0)\n                     &(data[measurement_col].isnull()),measurement_col] = model.predict(tmp_test[column])\n            total_na_filled_by_linear_model += len(tmp_test)\n\n        # others NA columns:\n        NA = data.loc[data[\"product_code\"] == code,nullValue_cols ].isnull().sum().sum()\n        model1 = KNNImputer(n_neighbors=3)\n        data.loc[data.product_code==code, feature] = model1.fit_transform(data.loc[data.product_code==code, feature])\n\n    data['measurement_avg'] = data[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n    df_train = data.iloc[:train.shape[0],:]\n    df_test = data.iloc[train.shape[0]:,:]\n\n    woe_encoder = WoEEncoder(variables=['attribute_0'])\n    woe_encoder.fit(df_train, target)\n    df_train = woe_encoder.transform(df_train)\n    df_test = woe_encoder.transform(df_test)\n    df_train['measurement(3*5)'] = df_train['measurement_3'] * df_train['measurement_5']\n    df_test['measurement(3*5)'] = df_test['measurement_3'] * df_test['measurement_5']\n    df_train['missing(3*5)'] = df_train['m5_missing'] * (df_train['m3_missing'])\n    df_test['missing(3*5)'] = df_test['m5_missing'] * (df_test['m3_missing'])\n    \n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:04.714524Z","iopub.execute_input":"2023-01-09T09:36:04.714926Z","iopub.status.idle":"2023-01-09T09:36:04.745090Z","shell.execute_reply.started":"2023-01-09T09:36:04.714876Z","shell.execute_reply":"2023-01-09T09:36:04.743548Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = data_pre_processing(data)\ndf_train['failure'] = target","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:04.746652Z","iopub.execute_input":"2023-01-09T09:36:04.747007Z","iopub.status.idle":"2023-01-09T09:36:30.549739Z","shell.execute_reply.started":"2023-01-09T09:36:04.746974Z","shell.execute_reply":"2023-01-09T09:36:30.548715Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def scale(train_data, val_data, test_data, feats):\n    scaler = StandardScaler()\n    scaled_train = scaler.fit_transform(train_data[feats])\n    scaled_val = scaler.transform(val_data[feats])\n    scaled_test = scaler.transform(test_data[feats])\n    new_train = train_data.copy()\n    new_val = val_data.copy()\n    new_test = test_data.copy()\n    new_train[feats] = scaled_train\n    new_val[feats] = scaled_val\n    new_test[feats] = scaled_test\n    return new_train, new_val, new_test","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:30.551255Z","iopub.execute_input":"2023-01-09T09:36:30.551985Z","iopub.status.idle":"2023-01-09T09:36:30.559274Z","shell.execute_reply.started":"2023-01-09T09:36:30.551948Z","shell.execute_reply":"2023-01-09T09:36:30.558321Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# features = ['loading','attribute_0' , 'measurement_17', 'measurement_0', 'measurement_1','measurement_2','area', 'm3_missing', 'm5_missing', \n#         'measurement_avg','measurement(3*5)','missing(3*5)'] # ,'count_null','ohe_a_7', 'ohe_a_6', 'ohe_a_8','measurement_4','measurement_9','measurement_7','measurement_6','measurement_8'\n\nfeatures = ['loading', 'measurement_17', 'm3_missing', 'm5_missing']\n\nN_FOLDS = 15\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=0)\ny_oof = np.zeros(df_train[features].shape[0])\ny_test = np.zeros(df_test[features].shape[0])\nlogistic_auc = 0\nix = 0\nlg_model=[]\nsm = SMOTE(random_state = 0, n_jobs = -1)\nclf = LogisticRegression(max_iter=1000, C=0.0005, penalty='l2',solver='newton-cg')\n\nfor train_ind, val_ind in skf.split(df_train[features], df_train[['failure']]):\n    print(f\"******* Fold {ix} ******* \")\n    tr_x, val_x = (\n        df_train[features].iloc[train_ind].reset_index(drop=True),\n        df_train[features].iloc[val_ind].reset_index(drop=True),\n    )\n    tr_y, val_y = (\n        df_train['failure'].iloc[train_ind].reset_index(drop=True),\n        df_train['failure'].iloc[val_ind].reset_index(drop=True),\n    )\n    \n    tr_x,val_x,test_x = scale(tr_x, val_x, df_test[features], features)\n    tr_x, tr_y = sm.fit_resample(tr_x, tr_y)\n    \n    clf.fit(tr_x, tr_y)\n    \n    preds = clf.predict_proba(val_x)[:,1]\n    \n    roc_score = roc_auc_score(val_y, preds)\n    \n    logistic_auc += roc_score/N_FOLDS\n\n    print('VAL_ROC-AUC:', round(roc_score, 5))\n    \n    y_oof[val_ind] = y_oof[val_ind] + preds\n\n    preds_test = clf.predict_proba(test_x)[:,1]\n    lg_model.append(preds_test)\n    y_test = y_test + preds_test / N_FOLDS\n    ix = ix + 1\n    \nprint(f\"{Fore.GREEN}{Style.BRIGHT}Average auc = {round(logistic_auc, 5)}{Style.RESET_ALL}\")\nprint(f\"{Fore.BLUE}{Style.BRIGHT}OOF auc = {round(roc_auc_score(df_train[['failure']], y_oof), 5)}{Style.RESET_ALL}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:30.560840Z","iopub.execute_input":"2023-01-09T09:36:30.561533Z","iopub.status.idle":"2023-01-09T09:36:35.702690Z","shell.execute_reply.started":"2023-01-09T09:36:30.561496Z","shell.execute_reply":"2023-01-09T09:36:35.699780Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"******* Fold 0 ******* \nVAL_ROC-AUC: 0.57099\n******* Fold 1 ******* \nVAL_ROC-AUC: 0.61327\n******* Fold 2 ******* \nVAL_ROC-AUC: 0.6161\n******* Fold 3 ******* \nVAL_ROC-AUC: 0.58769\n******* Fold 4 ******* \nVAL_ROC-AUC: 0.58217\n******* Fold 5 ******* \nVAL_ROC-AUC: 0.59751\n******* Fold 6 ******* \nVAL_ROC-AUC: 0.56965\n******* Fold 7 ******* \nVAL_ROC-AUC: 0.58988\n******* Fold 8 ******* \nVAL_ROC-AUC: 0.59358\n******* Fold 9 ******* \nVAL_ROC-AUC: 0.59867\n******* Fold 10 ******* \nVAL_ROC-AUC: 0.58264\n******* Fold 11 ******* \nVAL_ROC-AUC: 0.59998\n******* Fold 12 ******* \nVAL_ROC-AUC: 0.56863\n******* Fold 13 ******* \nVAL_ROC-AUC: 0.57455\n******* Fold 14 ******* \nVAL_ROC-AUC: 0.6107\n\u001b[32m\u001b[1mAverage auc = 0.5904\u001b[0m\n\u001b[34m\u001b[1mOOF auc = 0.59031\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = df_train[['failure']].copy(deep=True)\ny_pred = y_pred.rename(columns={\"failure\": \"prediction\"})\ny_pred[\"prediction\"] = y_oof\n\nroc_auc_score(df_train[['failure']],y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:35.705504Z","iopub.execute_input":"2023-01-09T09:36:35.706167Z","iopub.status.idle":"2023-01-09T09:36:35.765912Z","shell.execute_reply.started":"2023-01-09T09:36:35.706107Z","shell.execute_reply":"2023-01-09T09:36:35.764222Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.5903058051739523"},"metadata":{}}]},{"cell_type":"code","source":"sub_log = pd.read_csv('../input/tabular-playground-series-aug-2022/sample_submission.csv')\nsub_log['failure'] = y_test\n\nsub_log.to_csv(\"submission1.csv\", index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:35.777193Z","iopub.execute_input":"2023-01-09T09:36:35.778771Z","iopub.status.idle":"2023-01-09T09:36:35.853872Z","shell.execute_reply.started":"2023-01-09T09:36:35.778696Z","shell.execute_reply":"2023-01-09T09:36:35.852498Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"filename = f'model1.sav'\npickle.dump(clf, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:35.855225Z","iopub.execute_input":"2023-01-09T09:36:35.855663Z","iopub.status.idle":"2023-01-09T09:36:35.862591Z","shell.execute_reply.started":"2023-01-09T09:36:35.855627Z","shell.execute_reply":"2023-01-09T09:36:35.861153Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"clf = LGBMClassifier()\n\n\nfor train_ind, val_ind in skf.split(df_train[features], df_train[['failure']]):\n    print(f\"******* Fold {ix} ******* \")\n    tr_x, val_x = (\n        df_train[features].iloc[train_ind].reset_index(drop=True),\n        df_train[features].iloc[val_ind].reset_index(drop=True),\n    )\n    tr_y, val_y = (\n        df_train['failure'].iloc[train_ind].reset_index(drop=True),\n        df_train['failure'].iloc[val_ind].reset_index(drop=True),\n    )\n    \n    tr_x,val_x,test_x = scale(tr_x, val_x, df_test[features], features)\n    tr_x, tr_y = sm.fit_resample(tr_x, tr_y)\n    \n    clf.fit(tr_x, tr_y)\n    preds = clf.predict_proba(val_x)[:,1]\n    \n    roc_score = roc_auc_score(val_y, preds)\n    \n    logistic_auc += roc_score/N_FOLDS\n\n    print('VAL_ROC-AUC:', round(roc_score, 5))\n    \n    y_oof[val_ind] = y_oof[val_ind] + preds\n\n    preds_test = clf.predict_proba(test_x)[:,1]\n    lg_model.append(preds_test)\n    y_test = y_test + preds_test / N_FOLDS\n    ix = ix + 1\n    \nprint(f\"{Fore.GREEN}{Style.BRIGHT}Average auc = {round(logistic_auc, 5)}{Style.RESET_ALL}\")\nprint(f\"{Fore.BLUE}{Style.BRIGHT}OOF auc = {round(roc_auc_score(df_train[['failure']], y_oof), 5)}{Style.RESET_ALL}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:35.863992Z","iopub.execute_input":"2023-01-09T09:36:35.864417Z","iopub.status.idle":"2023-01-09T09:36:41.564924Z","shell.execute_reply.started":"2023-01-09T09:36:35.864385Z","shell.execute_reply":"2023-01-09T09:36:41.563475Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"******* Fold 15 ******* \nVAL_ROC-AUC: 0.54163\n******* Fold 16 ******* \nVAL_ROC-AUC: 0.56476\n******* Fold 17 ******* \nVAL_ROC-AUC: 0.60704\n******* Fold 18 ******* \nVAL_ROC-AUC: 0.55248\n******* Fold 19 ******* \nVAL_ROC-AUC: 0.56755\n******* Fold 20 ******* \nVAL_ROC-AUC: 0.57373\n******* Fold 21 ******* \nVAL_ROC-AUC: 0.56863\n******* Fold 22 ******* \nVAL_ROC-AUC: 0.5714\n******* Fold 23 ******* \nVAL_ROC-AUC: 0.57593\n******* Fold 24 ******* \nVAL_ROC-AUC: 0.55973\n******* Fold 25 ******* \nVAL_ROC-AUC: 0.54134\n******* Fold 26 ******* \nVAL_ROC-AUC: 0.58006\n******* Fold 27 ******* \nVAL_ROC-AUC: 0.54875\n******* Fold 28 ******* \nVAL_ROC-AUC: 0.55675\n******* Fold 29 ******* \nVAL_ROC-AUC: 0.58939\n\u001b[32m\u001b[1mAverage auc = 1.15701\u001b[0m\n\u001b[34m\u001b[1mOOF auc = 0.5808\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"sub_log = pd.read_csv('../input/tabular-playground-series-aug-2022/sample_submission.csv')\nsub_log['failure'] = y_test\n\nsub_log.to_csv(\"submission2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:41.566296Z","iopub.execute_input":"2023-01-09T09:36:41.566849Z","iopub.status.idle":"2023-01-09T09:36:41.629188Z","shell.execute_reply.started":"2023-01-09T09:36:41.566815Z","shell.execute_reply":"2023-01-09T09:36:41.628031Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"filename = f'model2.sav'\npickle.dump(clf, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T09:36:41.630735Z","iopub.execute_input":"2023-01-09T09:36:41.631109Z","iopub.status.idle":"2023-01-09T09:36:41.646475Z","shell.execute_reply.started":"2023-01-09T09:36:41.631075Z","shell.execute_reply":"2023-01-09T09:36:41.645047Z"},"trusted":true},"execution_count":40,"outputs":[]}]}